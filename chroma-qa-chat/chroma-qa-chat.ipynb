{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25612689-3184-4601-bb6c-0ec41bd60038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change kernel to Python 3 (ipykernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36689a7a-7585-4bb3-bb22-664efa960184",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssh -L 8000:gpn3001:8000 g00cjz00@t3-c4.nchc.org.tw\n"
     ]
    }
   ],
   "source": [
    "# ssh forwarding指令\n",
    "!echo ssh -L 8000:$(hostname -s):8000 $(whoami)@t3-c4.nchc.org.tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e86c77-4478-4800-af59-8b29604415a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kernel Image_pytorch_2.1.0-cuda11.8-cudnn8-devel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b473aaa1-f6cd-4f96-9acd-8d9a9f0f1d19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3.10  python3.8\n"
     ]
    }
   ],
   "source": [
    "# 套件目錄\n",
    "!ls ~/.local/lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d58331ab-d493-42de-b74e-860d0d18cb13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 新增可讀取套件安裝位置\n",
    "import os\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "Add_Binarry_Path=HOME+'/.local/bin'\n",
    "os.environ['PATH']=Add_Binarry_Path+':'+os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "056d2928-b72c-46ec-8051-86749debbc13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 安裝套件\n",
    "!pip install arxiv openai chromadb tiktoken pymupdf langchain chainlit transformers IProgress ipywidgets accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f04bcc9c-ba02-4a77-96e8-d5bad6c41c60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 安裝套件 GPTQ\n",
    "!pip install optimum -q\n",
    "!pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/  -q # Use cu117 if on CUDA 11.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b229218e-6208-4c8b-9fab-199a558b05c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-19 11:55:43 - Loaded .env file\n"
     ]
    }
   ],
   "source": [
    "# 確認套件是否完全安裝\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.document_loaders import (\n",
    "    PyMuPDFLoader,\n",
    ")\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.indexes import SQLRecordManager, index\n",
    "from langchain.schema import Document\n",
    "from langchain.schema.runnable import Runnable, RunnablePassthrough, RunnableConfig\n",
    "\n",
    "import chainlit as cl\n",
    "\n",
    "# GPTQ\n",
    "from transformers import AutoModelForCausalLM, pipeline, AutoTokenizer, TextStreamer\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cd94f57-121c-46f5-8f7b-4e76a40cce71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: (46949): No such process\n"
     ]
    }
   ],
   "source": [
    "# 刪除已啟動之chainlit 服務\n",
    "!ps -ef |grep chainlit  | awk '{print $2}' | xargs kill -9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b47da5cf-c8a3-4e93-a44f-5a70ae77b28e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-19 12:03:16 - Loaded .env file\n",
      "2023-11-19 12:03:18 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2023-11-19 12:03:19 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2023-11-19 12:03:22 - Your app is available at http://localhost:8000\n",
      "2023-11-19 12:03:33 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2023-11-19 12:03:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2023-11-19 12:04:23 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2023-11-19 12:04:25 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 啟動連線\n",
    "#ssh -L 8000:gpn3001:8000 g00cjz00@t3-c4.nchc.org.tw\n",
    "!chainlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7895327f-2722-4747-b5d7-1e51a6a66319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Image_pytorch_2.1.0-cuda11.8-cudnn8-devel",
   "language": "python",
   "name": "pytorch_2.1.0-cuda11.8-cudnn8-devel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
